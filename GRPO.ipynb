{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c720d4-d5c6-4ed2-b086-5e8026c81654",
   "metadata": {},
   "source": [
    "# Post Training: Reinforcement Learning from Human Feedback (RLHF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb945fa-d37e-451f-913f-ef6425a3fb90",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85191910-2548-409e-bd49-6df7880c726e",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78291c1",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
    "transformers.logging.set_verbosity_error()\n",
    "from trl import GRPOTrainer, GRPOConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd0b981",
   "metadata": {},
   "source": [
    "## Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d5b8172",
   "metadata": {
    "height": 795
   },
   "outputs": [],
   "source": [
    "def generate_responses(model, tokenizer, user_message=None, system_message=None, max_new_tokens=300, full_message=None):\n",
    "    #Formating chat using tokenizer's chat template:\n",
    "    #Preparing a list of chat messages (structured format):\n",
    "    if full_message:\n",
    "        messages = full_message\n",
    "    else:\n",
    "        messages = []\n",
    "    \n",
    "        #If a system message is provided, adding it first:\n",
    "        #System messages define assistant behavior (e.g., tone, personality):\n",
    "        if system_message:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "        #Add the user message as the next entry (it's a single-turn chat setup):\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    \n",
    "    #Tokenizing the prompt into input IDs and move to the model's device (CPU or GPU):\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False, #Return raw text prompt, not tokenized output.\n",
    "        add_generation_prompt=True, #Add assistant's cue to prompt generation.\n",
    "        enable_thinking=False, #Optional setting (used in some chat-aware models).\n",
    "    )\n",
    "    \n",
    "    #Disabling gradient calculation to save memory (inference-only):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    #Recommended to use vllm, sglang or TensorRT (For trying different menthods for inference):\n",
    "    with torch.no_grad():\n",
    "        #Generating output tokens from the model:\n",
    "        outputs = model.generate(\n",
    "            **inputs,   #Using a double pointer for unpacking the dictionary of inputs (model.generate(**inputs)) that is equivalent to (model.generate(input_ids=..., attention_mask=...)).\n",
    "            max_new_tokens=max_new_tokens, #Limit the number of tokens generated.\n",
    "            do_sample=False, #Disabling randomness (greedy decoding).\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    input_len = inputs[\"input_ids\"].shape[1] #Getting the length of the input (so we can extract only the newly generated tokens).\n",
    "    generated_ids = outputs[0][input_len:] #Slicing the output to keep only the new tokens (assistant's response).\n",
    "    \n",
    "    #Decoding the generated token IDs back into text:\n",
    "    #`skip_special_tokens=True` removing tokens like <|endoftext|>\n",
    "    #Strip() removes any leading/trailing whitespace or newline characters from the output string to keeps the model output clean and ready to display or use.\n",
    "    response = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6a6c38f",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "def test_model_with_questions(model, tokenizer, questions, \n",
    "                              system_message=None, title=\"Model Output\"):\n",
    "    #Printing section title for clarity\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    \n",
    "    #Looping through each question in the list, starting index at 1:\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        #Generating a model response for the current question:\n",
    "        #Passing in the question as user input and optional system message\n",
    "        response = generate_responses(model, tokenizer, question, \n",
    "                                      system_message)\n",
    "        #Print both the input question and the model's output response:\n",
    "        print(f\"\\nModel Input {i}:\\n{question}\\nModel Output {i}:\\n{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461977b4",
   "metadata": {
    "height": 489
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_name, use_gpu = False):\n",
    "    \n",
    "    #Loading tokenizer from the given model path or HuggingFace Hub name:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    #Loading causal language model (this is a GPT-style decoder-only model):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    \n",
    "    #If GPU is requested and available, move the model to CUDA:\n",
    "    if use_gpu:\n",
    "        model.to(\"cuda\")\n",
    "    \n",
    "    #If the tokenizer does not already have a chat template, defined a custom one:\n",
    "    #This template is used to format multi-turn conversations into a prompt string:\n",
    "    if not tokenizer.chat_template:\n",
    "        tokenizer.chat_template = \"\"\"{% for message in messages %}\n",
    "                {% if message['role'] == 'system' %}System: {{ message['content'] }}\\n\n",
    "                {% elif message['role'] == 'user' %}User: {{ message['content'] }}\\n\n",
    "                {% elif message['role'] == 'assistant' %}Assistant: {{ message['content'] }} <|endoftext|>\n",
    "                {% endif %}\n",
    "                {% endfor %}\"\"\"\n",
    "    \n",
    "    #Ensuring tokenizer has a pad token — fallback to eos token if missing:\n",
    "    if not tokenizer.pad_token:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    #Returning the ready-to-use model and tokenizer:   \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b1489-42cd-4d76-ad1a-936810cbbb06",
   "metadata": {},
   "source": [
    "## Prepare for evaluation dataset for Math: GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644d2813-5cce-4b47-a160-0c5a32c677ff",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "#Seting the computation device flag to disable GPU usage and runing the training or evaluation entirely on CPU.\n",
    "USE_GPU = False\n",
    "\n",
    "#Defining the system instruction prompt guiding the model to show reasoning steps and instructions to place the final numeric answer within a boxed format for easy extraction during reward evaluation.\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a helpful assistant that solves problems step-by-step. \"\n",
    "    \"Always include the final numeric answer inside \\\\boxed{}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69982ae0-755e-48cf-ba4c-3b83b091fd9a",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "#Defining reward function for both training using Online RL and evaluation with GSM8K.\n",
    "#Inputs to the function - models responses and the ground truth: \n",
    "def reward_func(completions, ground_truth, **kwargs):\n",
    "    #Regular expression match to capture content inside \\boxed{} from each model-generated response for automatic answer checking.\n",
    "    matches = [re.search(r\"\\\\boxed\\{(.*?)\\}\", completion[0]['content']) for completion in completions]\n",
    "    #Extracting the matched numeric string (very first match) from each regex result or assigns an empty string if no boxed content was found.\n",
    "    contents = [match.group(1) if match else \"\" for match in matches]\n",
    "    #Reward 1 if the content(c) is the same as the ground truth(gt), 0 otherwise\n",
    "    return [1.0 if c == gt else 0.0 for c, gt in zip(contents, ground_truth)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234e5b05-a493-4683-91fd-7417885efc0f",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sample Reward: [1.0]\n"
     ]
    }
   ],
   "source": [
    "#Created a simulated model output where the assistant’s response contains a numeric answer enclosed in \\boxed{} to test the reward function.\n",
    "sample_pred = [[{\"role\": \"assistant\", \n",
    "                 \"content\": r\"...Calculating the answer. \\boxed{72}\"}]]\n",
    "ground_truth = [\"72\"]\n",
    "#Calling the reward function using the sample model output(72) and ground truth(72) to compute the corresponding numeric reward value.\n",
    "reward = reward_func(sample_pred, ground_truth)\n",
    "print(f\"Positive Sample Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c273931-6827-4ee1-af1a-83a99bf94bf7",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sample Reward: [0.0]\n"
     ]
    }
   ],
   "source": [
    "#Created another simulated model output where the assistant’s response contains a numeric answer enclosed in \\boxed{} to test the reward function.\n",
    "sample_pred = [[{\"role\": \"assistant\", \n",
    "                 \"content\": r\"...Calculating the answer \\boxed{71}\"}]]\n",
    "ground_truth = [\"72\"]\n",
    "#Calling the reward function using the sample model output(71) and ground truth(72) to compute the corresponding numeric reward value.\n",
    "reward = reward_func(sample_pred, ground_truth)\n",
    "print(f\"Negative Sample Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c8041-39cd-4cd7-a2d7-0ef850959911",
   "metadata": {},
   "source": [
    "## Load the Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e82e0f1-0e30-4f8b-a603-e84d14cedf23",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7631a7d43c4f4d8f50404926383a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559cc5353bf5482bb6be514e97508d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "main/train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b767aaede64641b3b426952b180f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "main/test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b626c88391e4e118c864f1c8736b822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad06242118b942c8966d4b55f4ebf9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janet’s ducks lay 16 eggs per day. She eats th...</td>\n",
       "      <td>Janet sells 16 - 3 - 4 = &lt;&lt;16-3-4=9&gt;&gt;9 duck eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A robe takes 2 bolts of blue fiber and half th...</td>\n",
       "      <td>It takes 2/2=&lt;&lt;2/2=1&gt;&gt;1 bolt of white fiber\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh decides to try flipping a house.  He buys...</td>\n",
       "      <td>The cost of the house and repairs came out to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
       "      <td>He sprints 3*3=&lt;&lt;3*3=9&gt;&gt;9 times\\nSo he runs 9*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every day, Wendi feeds each of her chickens th...</td>\n",
       "      <td>If each chicken eats 3 cups of feed per day, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
       "1  A robe takes 2 bolts of blue fiber and half th...   \n",
       "2  Josh decides to try flipping a house.  He buys...   \n",
       "3  James decides to run 3 sprints 3 times a week....   \n",
       "4  Every day, Wendi feeds each of her chickens th...   \n",
       "\n",
       "                                              answer  \n",
       "0  Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...  \n",
       "1  It takes 2/2=<<2/2=1>>1 bolt of white fiber\\nS...  \n",
       "2  The cost of the house and repairs came out to ...  \n",
       "3  He sprints 3*3=<<3*3=9>>9 times\\nSo he runs 9*...  \n",
       "4  If each chicken eats 3 cups of feed per day, t...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Specifying the number of math problem samples to load from the evaluation dataset for quick testing and demonstration.\n",
    "data_num = 5\n",
    "#Loading the GSM8K math reasoning dataset from Hugging Face, selecting the test split, and limiting it to the first 5 examples for faster processing.\n",
    "eval_dataset = load_dataset(\"openai/gsm8k\", \"main\")[\"test\"].select(range(data_num))\n",
    "#Converting the selected dataset subset into a pandas DataFrame for easier inspection and visualization.\n",
    "sample_df = eval_dataset.to_pandas()\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1e8d415-01d1-45e3-a103-6a622f9e9a9c",
   "metadata": {
    "height": 268
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcfe4fdafee44a09b960bf7d214797a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Defining a function to extract clean numeric ground truth values and create structured prompts from each dataset example.\n",
    "def post_processing(example):\n",
    "    #Using a regular expression to locate the final numeric answer following the \"####\" marker in the GSM8K dataset answer text.\n",
    "    match = re.search(r\"####\\s*(-?\\d+)\", example[\"answer\"])\n",
    "    #Extracting the matched numeric string as the ground truth or assign None if no valid number is found.\n",
    "    example[\"ground_truth\"] = match.group(1) if match else None\n",
    "    #Building a formatted prompt containing both the system instruction and the user’s math question to prepare the input for model evaluation.\n",
    "    example[\"prompt\"] = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": example[\"question\"]}\n",
    "    ]\n",
    "    #Returning the example with new fields for ground truth and formatted prompt ready for further processing.\n",
    "    return example\n",
    "#Applying the post_processing function to every sample in the dataset and removing the original unprocessed text columns, leaving only the structured prompt and ground truth fields.\n",
    "eval_dataset = eval_dataset.map(post_processing).remove_columns([\"question\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fed78c2-ea93-4ac2-bd6f-5d4391de7c8d",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70000</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>540</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ground_truth                                             prompt\n",
       "0           18  [{'content': 'You are a helpful assistant that...\n",
       "1            3  [{'content': 'You are a helpful assistant that...\n",
       "2        70000  [{'content': 'You are a helpful assistant that...\n",
       "3          540  [{'content': 'You are a helpful assistant that...\n",
       "4           20  [{'content': 'You are a helpful assistant that..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#After the post-processing, the dataset only have two columns.\n",
    "#- One is ground truth number extracted from the original responses.\n",
    "#- Second, is a prompt, which is always a system prompt, followed by some questions.\n",
    "sample_df = eval_dataset.select(range(5)).to_pandas()\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c13dd-84e3-42ad-87dc-5f98772ec93c",
   "metadata": {},
   "source": [
    "## Load the model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e86f13c-c969-4c7e-8702-d074ee7a2ce6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "#Loading the Qwen 2.5-0.5B instruct model and evaluated on five loaded prompts from the GSM8K test dataset\n",
    "model, tokenizer = load_model_and_tokenizer(\"./models/Qwen/Qwen2.5-0.5B-Instruct\", USE_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb07589-049d-432e-8001-e6e9175ad806",
   "metadata": {
    "height": 523
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:15<01:00, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how much Janet makes at the farmers' market each day, we need to follow these steps:\n",
      "\n",
      "1. Calculate the total number of eggs laid by the ducks in one day.\n",
      "2. Determine how many eggs are eaten in one day.\n",
      "3. Subtract the number of eggs eaten from the total number of eggs to find out how many eggs are sold.\n",
      "4. Calculate the revenue from selling the eggs.\n",
      "\n",
      "Let's start with the first step:\n",
      "\n",
      "1. The ducks lay 16 eggs per day.\n",
      "2. Janet eats 3 eggs for breakfast every morning, so the number of eggs eaten in one day is:\n",
      "   \\[\n",
      "   16 - 3 = 13\n",
      "   \\]\n",
      "3. Janet bakes muffins for her friends every day, which means she bakes 4 muffins. So, the number of eggs baked in one day is:\n",
      "   \\[\n",
      "   13 + 4 = 17\n",
      "   \\]\n",
      "4. Janet sells the remaining eggs at the farmers' market. Since there are 16 eggs in total and 17 eggs are sold, the number of eggs left to sell is:\n",
      "   \\[\n",
      "   16 - 17 = -1\n",
      "   \\]\n",
      "   However, since it's not possible to sell fewer than 0 eggs, this indicates that Janet has no eggs left to sell. Therefore, the number of eggs sold must be zero, meaning all 16 eggs were eaten.\n",
      "Ground truth:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:25<00:36, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the total number of bolts needed for the robe, we need to calculate the amount of each type of fiber required and then sum them up.\n",
      "\n",
      "1. **Blue Fiber:**\n",
      "   - The problem states that it takes 2 bolts of blue fiber.\n",
      "   - Therefore, the number of bolts of blue fiber is \\(2\\).\n",
      "\n",
      "2. **White Fiber:**\n",
      "   - It takes half as much white fiber as blue fiber.\n",
      "   - Since 2 bolts of blue fiber require 2 bolts of white fiber, the number of bolts of white fiber is:\n",
      "     \\[\n",
      "     \\frac{2}{2} = 1\n",
      "     \\]\n",
      "\n",
      "3. **Total Number of Bolts:**\n",
      "   - To find the total number of bolts needed, we add the number of bolts of blue fiber and the number of bolts of white fiber:\n",
      "     \\[\n",
      "     2 + 1 = 3\n",
      "     \\]\n",
      "\n",
      "Thus, the total number of bolts required for the robe is \\(\\boxed{3}\\).\n",
      "Ground truth:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:40<00:27, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine Josh's profit from flipping his house, we need to follow these steps:\n",
      "\n",
      "1. **Calculate the total cost of the house:**\n",
      "   - The house costs $80,000.\n",
      "   - Josh also spends an additional $50,000 on repairs.\n",
      "\n",
      "2. **Determine the net cost after repairs:**\n",
      "   - Net cost = Total cost - Cost of repairs\n",
      "   - Net cost = $80,000 - $50,000 = $30,000\n",
      "\n",
      "3. **Calculate the increase in value due to repairs:**\n",
      "   - The value of the house increased by 150%.\n",
      "   - Increase in value = Percentage increase × Original value\n",
      "   - Increase in value = 150% × $80,000\n",
      "   - Increase in value = 1.5 × $80,000 = $120,000\n",
      "\n",
      "4. **Determine the new value of the house:**\n",
      "   - New value = Original value + Increase in value\n",
      "   - New value = $80,000 + $120,000 = $200,000\n",
      "\n",
      "5. **Calculate the profit:**\n",
      "   - Profit = New value - Net cost\n",
      "   - Profit = $200,000 - $30,000 = $170,\n",
      "Ground truth:  70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:49<00:11, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how many total meters James runs in a week, we need to follow these steps:\n",
      "\n",
      "1. Calculate the distance James runs in one sprint.\n",
      "2. Multiply the distance of one sprint by the number of sprints he runs per week.\n",
      "\n",
      "First, let's find out how far James runs in one sprint:\n",
      "\\[ \\text{Distance per sprint} = 60 \\text{ meters} \\]\n",
      "\n",
      "Next, since James runs 3 sprints per week, we multiply the distance of one sprint by 3:\n",
      "\\[ \\text{Total distance per week} = 60 \\text{ meters/sprint} \\times 3 \\text{ sprints/week} \\]\n",
      "\\[ \\text{Total distance per week} = 180 \\text{ meters} \\]\n",
      "\n",
      "So, the total distance James runs in a week is:\n",
      "\\[\n",
      "\\boxed{180}\n",
      "\\]\n",
      "Ground truth:  540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:05<00:00, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how many cups of feed Wendi needs for the final meal of the day, we can follow these steps:\n",
      "\n",
      "1. Calculate the total amount of feed needed for all the chickens.\n",
      "2. Determine how much feed is given away in the morning and the afternoon.\n",
      "3. Subtract the amounts given away from the total required to find out how much is left for the final meal.\n",
      "\n",
      "First, let's calculate the total amount of feed needed for all the chickens:\n",
      "- Each chicken gets 3 cups of feed per day.\n",
      "- There are 20 chickens in total.\n",
      "\n",
      "So, the total amount of feed needed is:\n",
      "\\[ 20 \\text{ chickens} \\times 3 \\text{ cups/chicken} = 60 \\text{ cups} \\]\n",
      "\n",
      "Next, we calculate the amount of feed given away in the morning and the afternoon:\n",
      "- In the morning: \\( 15 \\text{ cups} \\)\n",
      "- In the afternoon: \\( 25 \\text{ cups} \\)\n",
      "\n",
      "Now, we subtract the amounts given away from the total required:\n",
      "\\[ 60 \\text{ cups} - (15 \\text{ cups} + 25 \\text{ cups}) = 60 \\text{ cups} - 40 \\text{ cups} = 20 \\text{ cups} \\]\n",
      "\n",
      "Therefore, the number of cups of feed Wendi needs to give her chickens in the final meal of the day is:\n",
      "\\[\n",
      "Ground truth:  20\n",
      "Evaluation Accuracy: 20.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Storing predictions and ground truths:\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for example in tqdm(eval_dataset):\n",
    "    #Going through the post processed dataset:\n",
    "    #Extracting the structured prompt that includes the system instruction and user’s math question.\n",
    "    input_prompt = example[\"prompt\"]\n",
    "    #Retrieving the numeric ground truth answer from the processed dataset for later comparison.\n",
    "    ground_truth = example[\"ground_truth\"]\n",
    "    #Runing the model to generate an answer:\n",
    "    with torch.no_grad():\n",
    "        response = generate_responses(model, tokenizer, \n",
    "                                      full_message = input_prompt) \n",
    "    #Appending the generated model response to the list in the same structured format expected by the reward function.\n",
    "    all_preds.append([{\"role\": \"assistant\", \"content\": response}])\n",
    "    #Appending the corresponding ground truth label to the list to align with the prediction order.\n",
    "    all_labels.append(ground_truth)\n",
    "    print(response)\n",
    "    print(\"Ground truth: \", ground_truth)\n",
    "\n",
    "# 3.Evaluating using reward_func\n",
    "#Applying the previously defined reward function to all generated responses and ground truths to compute scores.\n",
    "rewards = reward_func(all_preds, all_labels)\n",
    "\n",
    "# 4. Reporting accuracy:\n",
    "#Calculating overall evaluation accuracy as the proportion of correct responses across all evaluated examples.\n",
    "accuracy = sum(rewards) / len(rewards)\n",
    "print(f\"Evaluation Accuracy: {accuracy:.2%}\")\n",
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35fe400",
   "metadata": {
    "height": 30
   },
   "source": [
    "#### Until here I have completed designing the evaluation process, and now will do the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b31f32-5eaf-476c-8e91-2e28efdc4d3c",
   "metadata": {},
   "source": [
    "## Loading the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01c515a8-3728-45fa-88cc-6eb4de839839",
   "metadata": {
    "height": 251
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b605bdeb9a624c89839328e68b2cdd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ground_truth': '72', 'prompt': [{'content': 'You are a helpful assistant that solves problems step-by-step. Always include the final numeric answer inside \\\\boxed{}.', 'role': 'system'}, {'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'role': 'user'}]}\n"
     ]
    }
   ],
   "source": [
    "#Downloading the full GSM8K dataset from Hugging Face which contains grade school math problems and their step-by-step solutions.\n",
    "dataset = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "#Selecting the training split of the GSM8K dataset to be used for model training with online reinforcement learning.\n",
    "train_dataset = dataset[\"train\"]\n",
    " \n",
    "# Apply to dataset\n",
    "#Applying the previously defined post_processing function to each sample to extract numeric ground truths and format prompts for training input.\n",
    "train_dataset = train_dataset.map(post_processing)\n",
    "#Removing the original question and answer columns to keep only the structured prompt and ground truth fields needed for training.\n",
    "train_dataset = train_dataset.remove_columns([\"question\", \"answer\"])\n",
    "#Reducing the dataset to the first 10 samples when running on CPU to make the training process faster and lightweight.\n",
    "if not USE_GPU:\n",
    "    train_dataset = train_dataset.select(range(10))\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57436e8c-9b07-4da1-8fae-4430c6617b36",
   "metadata": {},
   "source": [
    "## GRPO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d678274-5768-4cea-ae20-051488e5d0f3",
   "metadata": {
    "height": 302
   },
   "outputs": [],
   "source": [
    "config = GRPOConfig(\n",
    "    #Accumulating gradients over 8 mini-batches before performing a single weight update to simulate a larger effective batch size and stabilize training.\n",
    "    gradient_accumulation_steps=8,\n",
    "    #Seting the number of samples processed per device in one forward and backward pass to one for low-memory environments like CPU.\n",
    "    per_device_train_batch_size=1,\n",
    "    #Specifying how many responses the model should generate per prompt to form a comparison group in GRPO where rewards are computed relatively among responses.\n",
    "    num_generations=4, # Can set as high as 64 or 128\n",
    "    #Runing one full pass over the training dataset since this demonstration focuses on showing the pipeline rather than long convergence.\n",
    "    num_train_epochs=1,\n",
    "    #Defining a small step size for model weight updates to ensure stable learning during reinforcement optimization.\n",
    "    learning_rate=5e-6,\n",
    "    #Instructing the trainer to log intermediate metrics every two steps to monitor progress frequently during small-scale runs.\n",
    "    logging_steps=2,\n",
    "    #Disables GPU usage if USE_GPU is False ensuring the entire training stays on CPU.\n",
    "    no_cuda= not USE_GPU\n",
    ")\n",
    "#Creating a configuration object for GRPO training containing all major hyperparameters and device setup instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc2d5896-6fd6-43d2-85f1-dacbd594f4cf",
   "metadata": {
    "height": 268
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 98.1195, 'train_samples_per_second': 0.102, 'train_steps_per_second': 0.01, 'train_loss': 0.0, 'completion_length': 168.4375, 'rewards/reward_func': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'kl': 0.0, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1, training_loss=0.0, metrics={'train_runtime': 98.1195, 'train_samples_per_second': 0.102, 'train_steps_per_second': 0.01, 'total_flos': 0.0, 'train_loss': 0.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading a small instruction-tuned model and its tokenizer for GRPO so that training is feasible on CPU-only setups.\n",
    "model, tokenizer = load_model_and_tokenizer(\"./models/HuggingFaceTB/SmolLM2-135M-Instruct\", USE_GPU)\n",
    "\n",
    "grpo_trainer = GRPOTrainer(\n",
    "    #Suppling the policy model whose weights will be updated by GRPO during training.\n",
    "    model=model,\n",
    "    #Passes the GRPO configuration that defines batch size, number of generations per prompt, learning rate, logging steps, and device behavior.\n",
    "    args=config,\n",
    "    #Providing the verifiable reward function that extracts \\boxed{} answers and returns rewards which GRPO will use to compute group-relative advantages.\n",
    "    reward_funcs=reward_func,\n",
    "    #Giving the preprocessed training dataset where each item contains a formatted prompt and a numeric ground truth for reward calculation.\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "#Starting the GRPO training loop where multiple responses per prompt are generated, scored by the reward function, and used to update the policy via relative advantages.\n",
    "grpo_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a33533-3f0c-4d1c-a5ef-f0ba1ff61a5f",
   "metadata": {},
   "source": [
    "## Results on the small trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5521a00a-88d8-4ad9-b134-12ea94e76984",
   "metadata": {
    "height": 421
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:07<00:29,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Janet's ducks lay 16 eggs per day.\n",
      "She eats three for breakfast every morning and bakes muffins for her friends every day with four.\n",
      "She sells the remainder at the farmers' market daily for $2 per fresh duck egg.\n",
      "She makes 16 eggs / 3 for breakfast = 6 eggs per day.\n",
      "She sells the remainder at the farmers' market daily for $2 per fresh duck egg.\n",
      "She makes 6 eggs / 4 for breakfast = 1.5 eggs per day.\n",
      "She makes 6 eggs / 4 for breakfast = 1.5 eggs per day.\n",
      "She makes 1.5 eggs / 2 for breakfast = 1.25 eggs per day.\n",
      "She makes 1.25 eggs / 4 for breakfast = 3.25 eggs per day.\n",
      "She makes 3.25 eggs / 2 for breakfast = 1.5 eggs per day.\n",
      "She makes 1.5 eggs / 3 for breakfast = 0.5 eggs per day.\n",
      "She makes 0.5 eggs / 4 for breakfast = 0.125 eggs per day.\n",
      "She makes 0.125 eggs / 2 for breakfast = 0.0625 eggs per day.\n",
      "She makes 0.0625 eggs / 3 for breakfast = 0.025 eggs per day.\n",
      "Ground truth:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [00:12<00:18,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this problem, we need to consider the total amount of fiber required and the amount of blue fiber needed.\n",
      "\n",
      "First, we need to find the total amount of blue fiber required. Since we have 2 bolts of blue fiber and half the amount of white fiber, we can multiply the number of bolts by the amount of blue fiber needed.\n",
      "\n",
      "The total amount of blue fiber required is 2 * 0.5 = 0.10 blue fiber.\n",
      "\n",
      "Now, we need to find the total amount of white fiber required. Since we have 1 bolt of white fiber and half the amount of blue fiber, we can multiply the number of bolts by the amount of white fiber needed.\n",
      "\n",
      "The total amount of white fiber required is 1 * 0.5 = 0.5 bolts.\n",
      "\n",
      "Finally, we can find the total amount of bolts by adding the blue fiber and white fiber together: 0.10 blue fiber + 0.5 bolts = 0.65 bolts.\n",
      "\n",
      "So, the robe takes 0.65 bolts of blue fiber and 0.5 bolts of white fiber.\n",
      "Ground truth:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [00:15<00:09,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find the profit, we need to calculate the difference between the original price of the house ($80,000) and the new price of the house ($85,000).\n",
      "\n",
      "The original price was $80,000.\n",
      "\n",
      "The new price is $85,000.\n",
      "\n",
      "The difference is $85,000 - $80,000 = $5,000.\n",
      "\n",
      "The profit is $5,000.\n",
      "\n",
      "So, Josh made a profit of $5,000.\n",
      "Ground truth:  70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [00:17<00:03,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James runs 60 meters each sprint.\n",
      "He runs 3 sprints x 60 meters = 180 meters.\n",
      "He runs 180 meters x 3 sprints = 540 meters.\n",
      "So, James runs 540 meters a week.\n",
      "#### 540\n",
      "The answer is: 540\n",
      "Ground truth:  540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:25<00:00,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Determine the total number of cups of feed given to the chickens in the morning.\n",
      "\n",
      "Wendi feeds her chickens 15 cups of feed in the morning.\n",
      "\n",
      "Step 2: Determine the total number of cups of feed given to the chickens in the afternoon.\n",
      "\n",
      "Wendi gives her chickens another 25 cups of feed in the afternoon.\n",
      "\n",
      "Step 3: Determine the total number of cups of feed given to the chickens in the final meal of the day.\n",
      "\n",
      "Wendi gives her chickens 15 cups of feed in the morning, 25 cups in the afternoon, and 15 cups in the evening.\n",
      "\n",
      "Step 4: Calculate the total number of cups of feed given to the chickens in the final meal of the day.\n",
      "\n",
      "Total number of cups of feed given to the chickens in the morning = 15 cups\n",
      "Total number of cups of feed given to the chickens in the afternoon = 25 cups\n",
      "Total number of cups of feed given to the chickens in the evening = 15 cups\n",
      "\n",
      "Step 5: Calculate the total number of cups of feed given to the chickens in the final meal of the day.\n",
      "\n",
      "Total number of cups of feed given to the chickens in the morning = 15 cups\n",
      "Total number of cups of feed given to the chickens in the afternoon = 25 cups\n",
      "Total number of cups of feed given to the chickens\n",
      "Ground truth:  20\n",
      "Evaluation Accuracy: 0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = grpo_trainer.model\n",
    "\n",
    "# Store predictions and ground truths\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for example in tqdm(eval_dataset):\n",
    "    input_prompt = example[\"prompt\"]\n",
    "    ground_truth = example[\"ground_truth\"]\n",
    "    # Run the model to generate an answer\n",
    "    with torch.no_grad():\n",
    "        response = generate_responses(model, tokenizer, \n",
    "                                      full_message = input_prompt) \n",
    "    all_preds.append([{\"role\": \"assistant\", \"content\": response}])\n",
    "    all_labels.append(ground_truth)\n",
    "    print(response)\n",
    "    print(\"Ground truth: \", ground_truth)\n",
    "\n",
    "# 3. Evaluate using reward_func\n",
    "rewards = reward_func(all_preds, all_labels)\n",
    "\n",
    "# 4. Report accuracy\n",
    "accuracy = sum(rewards) / len(rewards)\n",
    "print(f\"Evaluation Accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39edfd3c-0ea7-43cd-90d6-6c0d8e2216e6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa3e26-e46c-409f-be94-7475e6c91dbe",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5db8c-fe2c-46e5-b9ab-2ce6ec309fb1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8623c-8125-48bf-b482-8147b0d75831",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a42fb-9ea9-4e33-90d0-c0bf1b676439",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b1cfb-6cc0-4a76-be8a-a1a10f60b7b9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
