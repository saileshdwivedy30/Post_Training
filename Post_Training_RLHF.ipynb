{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c720d4-d5c6-4ed2-b086-5e8026c81654",
   "metadata": {},
   "source": [
    "# Post Training: Reinforcement Learning from Human Feedback (RLHF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb945fa-d37e-451f-913f-ef6425a3fb90",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85191910-2548-409e-bd49-6df7880c726e",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3304e49d-bd1e-469b-a5b4-5edb16ecf344",
   "metadata": {
    "height": 165
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
    "transformers.logging.set_verbosity_error()\n",
    "from trl import GRPOTrainer, GRPOConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070243f",
   "metadata": {
    "height": 30
   },
   "source": [
    "## Helper Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df34f1e",
   "metadata": {
    "height": 791
   },
   "outputs": [],
   "source": [
    "def generate_responses(model, tokenizer, user_message=None, system_message=None, max_new_tokens=300, full_message=None):\n",
    "    #Formating chat using tokenizer's chat template:\n",
    "    #Preparing a list of chat messages (structured format):\n",
    "    if full_message:\n",
    "        messages = full_message\n",
    "    else:\n",
    "        messages = []\n",
    "    \n",
    "        #If a system message is provided, adding it first:\n",
    "        #System messages define assistant behavior (tone, personality):\n",
    "        if system_message:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "        #Add the user message as the next entry (it is a single turn chat setup where user and assistant have only one interaction):\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "    \n",
    "    \n",
    "    #Tokenizing the prompt into input IDs and move to the model's device (CPU or GPU):\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False, #Return raw text prompt, not tokenized output.\n",
    "        add_generation_prompt=True, #Add assistant's cue to prompt generation.\n",
    "        enable_thinking=False, #Optional setting (used in some chat aware models).\n",
    "    )\n",
    "    \n",
    "    #Disabling gradient calculation to save memory (inference only):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        #Generating output tokens from the model:\n",
    "        outputs = model.generate(\n",
    "            **inputs,   #Using a double pointer for unpacking the dictionary of inputs (model.generate(**inputs)) that is equivalent to (model.generate(input_ids=..., attention_mask=...)).\n",
    "            max_new_tokens=max_new_tokens, #Limit the number of tokens generated.\n",
    "            do_sample=False, #Disabling randomness (greedy decoding).\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    input_len = inputs[\"input_ids\"].shape[1] #Getting the length of the input (so we can extract only the newly generated tokens).\n",
    "    generated_ids = outputs[0][input_len:] #Slicing the output to keep only the new tokens (assistant's response).\n",
    "    \n",
    "    #Decoding the generated token IDs back into text:\n",
    "    #`skip_special_tokens=True` removing tokens like <|endoftext|>\n",
    "    #Strip() removes any leading/trailing whitespace or newline characters from the output string to keeps the model output clean and ready to display or use.\n",
    "    response = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0c29c",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "def test_model_with_questions(model, tokenizer, questions, \n",
    "                              system_message=None, title=\"Model Output\"):\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    \n",
    "    #Looping through each question in the list, starting index at 1:\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        #Generating a model response for the current question:\n",
    "        #Passing in the question as user input and optional system message\n",
    "        response = generate_responses(model, tokenizer, question, \n",
    "                                      system_message)\n",
    "        #Print both the input question and the model's output response:\n",
    "        print(f\"\\nModel Input {i}:\\n{question}\\nModel Output {i}:\\n{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b4eef7",
   "metadata": {
    "height": 489
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_name, use_gpu = False):\n",
    "    \n",
    "    #Loading tokenizer from the given model path or HuggingFace Hub name:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    #Loading causal language model (this is a GPT style decoder only model):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    \n",
    "    #If GPU is requested and available, move the model to CUDA:\n",
    "    if use_gpu:\n",
    "        model.to(\"cuda\")\n",
    "    \n",
    "    #If the tokenizer does not already have a chat template, defined a custom one:\n",
    "    #This template is used to format multi turn conversations into a prompt string:\n",
    "    if not tokenizer.chat_template:\n",
    "        tokenizer.chat_template = \"\"\"{% for message in messages %}\n",
    "                {% if message['role'] == 'system' %}System: {{ message['content'] }}\\n\n",
    "                {% elif message['role'] == 'user' %}User: {{ message['content'] }}\\n\n",
    "                {% elif message['role'] == 'assistant' %}Assistant: {{ message['content'] }} <|endoftext|>\n",
    "                {% endif %}\n",
    "                {% endfor %}\"\"\"\n",
    "    \n",
    "    #Ensuring tokenizer has a pad token — fallback to eos token if missing:\n",
    "    if not tokenizer.pad_token:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    #Returning the ready to use model and tokenizer:   \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b1489-42cd-4d76-ad1a-936810cbbb06",
   "metadata": {},
   "source": [
    "## Prepare for evaluation dataset for Math: GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644d2813-5cce-4b47-a160-0c5a32c677ff",
   "metadata": {
    "height": 144
   },
   "outputs": [],
   "source": [
    "#Seting the computation device flag to disable GPU usage and runing the training or evaluation entirely on CPU.\n",
    "USE_GPU = False\n",
    "\n",
    "#Defining the system instruction prompt guiding the model to show reasoning steps and instructions to place the final numeric answer within a boxed format for easy extraction during reward evaluation.\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a helpful assistant that solves problems step-by-step. \"\n",
    "    \"Always include the final numeric answer inside \\\\boxed{}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69982ae0-755e-48cf-ba4c-3b83b091fd9a",
   "metadata": {
    "height": 163
   },
   "outputs": [],
   "source": [
    "#Defining reward function for both training using Online RL and evaluation with GSM8K.\n",
    "#Inputs to the function - models responses and the ground truth: \n",
    "def reward_func(completions, ground_truth, **kwargs):\n",
    "    #Regular expression match to capture content inside \\boxed{} from each model-generated response for automatic answer checking.\n",
    "    matches = [re.search(r\"\\\\boxed\\{(.*?)\\}\", completion[0]['content']) for completion in completions]\n",
    "    #Extracting the matched numeric string (very first match) from each regex result or assigns an empty string if no boxed content was found.\n",
    "    contents = [match.group(1) if match else \"\" for match in matches]\n",
    "    #Reward 1 if the content(c) is the same as the ground truth(gt), 0 otherwise\n",
    "    return [1.0 if c == gt else 0.0 for c, gt in zip(contents, ground_truth)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "234e5b05-a493-4683-91fd-7417885efc0f",
   "metadata": {
    "height": 130
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sample Reward: [1.0]\n"
     ]
    }
   ],
   "source": [
    "#Created a simulated model output where the assistant’s response contains a numeric answer enclosed in \\boxed{} to test the reward function.\n",
    "sample_pred = [[{\"role\": \"assistant\", \n",
    "                 \"content\": r\"...Calculating the answer. \\boxed{72}\"}]]\n",
    "ground_truth = [\"72\"]\n",
    "#Calling the reward function using the sample model output(72) and ground truth(72) to compute the corresponding numeric reward value.\n",
    "reward = reward_func(sample_pred, ground_truth)\n",
    "print(f\"Positive Sample Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c273931-6827-4ee1-af1a-83a99bf94bf7",
   "metadata": {
    "height": 131
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sample Reward: [0.0]\n"
     ]
    }
   ],
   "source": [
    "#Created another simulated model output where the assistant’s response contains a numeric answer enclosed in \\boxed{} to test the reward function.\n",
    "sample_pred = [[{\"role\": \"assistant\", \n",
    "                 \"content\": r\"...Calculating the answer \\boxed{71}\"}]]\n",
    "ground_truth = [\"72\"]\n",
    "#Calling the reward function using the sample model output(71) and ground truth(72) to compute the corresponding numeric reward value.\n",
    "reward = reward_func(sample_pred, ground_truth)\n",
    "print(f\"Negative Sample Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c8041-39cd-4cd7-a2d7-0ef850959911",
   "metadata": {},
   "source": [
    "## Load the Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e82e0f1-0e30-4f8b-a603-e84d14cedf23",
   "metadata": {
    "height": 134
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janet’s ducks lay 16 eggs per day. She eats th...</td>\n",
       "      <td>Janet sells 16 - 3 - 4 = &lt;&lt;16-3-4=9&gt;&gt;9 duck eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A robe takes 2 bolts of blue fiber and half th...</td>\n",
       "      <td>It takes 2/2=&lt;&lt;2/2=1&gt;&gt;1 bolt of white fiber\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh decides to try flipping a house.  He buys...</td>\n",
       "      <td>The cost of the house and repairs came out to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
       "      <td>He sprints 3*3=&lt;&lt;3*3=9&gt;&gt;9 times\\nSo he runs 9*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every day, Wendi feeds each of her chickens th...</td>\n",
       "      <td>If each chicken eats 3 cups of feed per day, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Janet’s ducks lay 16 eggs per day. She eats th...   \n",
       "1  A robe takes 2 bolts of blue fiber and half th...   \n",
       "2  Josh decides to try flipping a house.  He buys...   \n",
       "3  James decides to run 3 sprints 3 times a week....   \n",
       "4  Every day, Wendi feeds each of her chickens th...   \n",
       "\n",
       "                                              answer  \n",
       "0  Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...  \n",
       "1  It takes 2/2=<<2/2=1>>1 bolt of white fiber\\nS...  \n",
       "2  The cost of the house and repairs came out to ...  \n",
       "3  He sprints 3*3=<<3*3=9>>9 times\\nSo he runs 9*...  \n",
       "4  If each chicken eats 3 cups of feed per day, t...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Specifying the number of math problem samples to load from the evaluation dataset for quick testing and demonstration.\n",
    "data_num = 5\n",
    "#Loading the GSM8K math reasoning dataset from Hugging Face, selecting the test split, and limiting it to the first 5 examples for faster processing.\n",
    "eval_dataset = load_dataset(\"openai/gsm8k\", \"main\")[\"test\"].select(range(data_num))\n",
    "#Converting the selected dataset subset into a pandas DataFrame for easier inspection and visualization.\n",
    "sample_df = eval_dataset.to_pandas()\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1e8d415-01d1-45e3-a103-6a622f9e9a9c",
   "metadata": {
    "height": 275
   },
   "outputs": [],
   "source": [
    "#Defining a function to extract clean numeric ground truth values and create structured prompts from each dataset example.\n",
    "def post_processing(example):\n",
    "    #Using a regular expression to locate the final numeric answer following the \"####\" marker in the GSM8K dataset answer text.\n",
    "    match = re.search(r\"####\\s*(-?\\d+)\", example[\"answer\"])\n",
    "    #Extracting the matched numeric string as the ground truth or assign None if no valid number is found.\n",
    "    example[\"ground_truth\"] = match.group(1) if match else None\n",
    "    #Building a formatted prompt containing both the system instruction and the user’s math question to prepare the input for model evaluation.\n",
    "    example[\"prompt\"] = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": example[\"question\"]}\n",
    "    ]\n",
    "    #Returning the example with new fields for ground truth and formatted prompt ready for further processing.\n",
    "    return example\n",
    "#Applying the post_processing function to every sample in the dataset and removing the original unprocessed text columns, leaving only the structured prompt and ground truth fields.\n",
    "eval_dataset = eval_dataset.map(post_processing).remove_columns([\"question\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed78c2-ea93-4ac2-bd6f-5d4391de7c8d",
   "metadata": {
    "height": 96
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70000</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>540</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>[{'content': 'You are a helpful assistant that...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ground_truth                                             prompt\n",
       "0           18  [{'content': 'You are a helpful assistant that...\n",
       "1            3  [{'content': 'You are a helpful assistant that...\n",
       "2        70000  [{'content': 'You are a helpful assistant that...\n",
       "3          540  [{'content': 'You are a helpful assistant that...\n",
       "4           20  [{'content': 'You are a helpful assistant that..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#After the post processing, the dataset only have two columns.\n",
    "#- One is ground truth number extracted from the original responses.\n",
    "#- Second, is a prompt, which is always a system prompt, followed by some questions.\n",
    "sample_df = eval_dataset.select(range(5)).to_pandas()\n",
    "display(sample_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c13dd-84e3-42ad-87dc-5f98772ec93c",
   "metadata": {},
   "source": [
    "## Load the model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e86f13c-c969-4c7e-8702-d074ee7a2ce6",
   "metadata": {
    "height": 49
   },
   "outputs": [],
   "source": [
    "#Loading the Qwen 2.5-0.5B instruct model and evaluated on five loaded prompts from the GSM8K test dataset\n",
    "model, tokenizer = load_model_and_tokenizer(\"./models/Qwen/Qwen2.5-0.5B-Instruct\", USE_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdb07589-049d-432e-8001-e6e9175ad806",
   "metadata": {
    "height": 525
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:15<01:00, 15.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how much Janet makes at the farmers' market each day, we need to follow these steps:\n",
      "\n",
      "1. Calculate the total number of eggs laid by the ducks in one day.\n",
      "2. Determine how many eggs are eaten in one day.\n",
      "3. Subtract the number of eggs eaten from the total number of eggs to find out how many eggs are sold.\n",
      "4. Calculate the revenue from selling the eggs.\n",
      "\n",
      "Let's start with the first step:\n",
      "\n",
      "1. The ducks lay 16 eggs per day.\n",
      "2. Janet eats 3 eggs for breakfast every morning, so the number of eggs eaten in one day is:\n",
      "   \\[\n",
      "   16 - 3 = 13\n",
      "   \\]\n",
      "3. Janet bakes muffins for her friends every day, which means she bakes 4 muffins. So, the number of eggs baked in one day is:\n",
      "   \\[\n",
      "   13 + 4 = 17\n",
      "   \\]\n",
      "4. Janet sells the remaining eggs at the farmers' market. Since there are 16 eggs in total and 17 eggs are sold, the number of eggs left to sell is:\n",
      "   \\[\n",
      "   16 - 17 = -1\n",
      "   \\]\n",
      "   However, since it's not possible to sell fewer than 0 eggs, this indicates that Janet has no eggs left to sell. Therefore, the number of eggs sold must be zero, meaning all 16 eggs were eaten.\n",
      "Ground truth:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|████      | 2/5 [00:25<00:37, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the total number of bolts needed for the robe, we need to calculate the amount of each type of fiber required and then sum them up.\n",
      "\n",
      "1. **Blue Fiber:**\n",
      "   - The problem states that it takes 2 bolts of blue fiber.\n",
      "   - Therefore, the number of bolts of blue fiber is \\(2\\).\n",
      "\n",
      "2. **White Fiber:**\n",
      "   - It takes half as much white fiber as blue fiber.\n",
      "   - Since 2 bolts of blue fiber require 2 bolts of white fiber, the number of bolts of white fiber is:\n",
      "     \\[\n",
      "     \\frac{2}{2} = 1\n",
      "     \\]\n",
      "\n",
      "3. **Total Number of Bolts:**\n",
      "   - To find the total number of bolts needed, we add the number of bolts of blue fiber and the number of bolts of white fiber:\n",
      "     \\[\n",
      "     2 + 1 = 3\n",
      "     \\]\n",
      "\n",
      "Thus, the total number of bolts required for the robe is \\(\\boxed{3}\\).\n",
      "Ground truth:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|██████    | 3/5 [00:40<00:27, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine Josh's profit from flipping his house, we need to follow these steps:\n",
      "\n",
      "1. **Calculate the total cost of the house:**\n",
      "   - The house costs $80,000.\n",
      "   - Josh also spends an additional $50,000 on repairs.\n",
      "\n",
      "2. **Determine the net cost after repairs:**\n",
      "   - Net cost = Total cost - Cost of repairs\n",
      "   - Net cost = $80,000 - $50,000 = $30,000\n",
      "\n",
      "3. **Calculate the increase in value due to repairs:**\n",
      "   - The value of the house increased by 150%.\n",
      "   - Increase in value = Percentage increase × Original value\n",
      "   - Increase in value = 150% × $80,000\n",
      "   - Increase in value = 1.5 × $80,000 = $120,000\n",
      "\n",
      "4. **Determine the new value of the house:**\n",
      "   - New value = Original value + Increase in value\n",
      "   - New value = $80,000 + $120,000 = $200,000\n",
      "\n",
      "5. **Calculate the profit:**\n",
      "   - Profit = New value - Net cost\n",
      "   - Profit = $200,000 - $30,000 = $170,\n",
      "Ground truth:  70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|████████  | 4/5 [00:49<00:11, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how many total meters James runs in a week, we need to follow these steps:\n",
      "\n",
      "1. Calculate the distance James runs in one sprint.\n",
      "2. Multiply the distance of one sprint by the number of sprints he runs per week.\n",
      "\n",
      "First, let's find out how far James runs in one sprint:\n",
      "\\[ \\text{Distance per sprint} = 60 \\text{ meters} \\]\n",
      "\n",
      "Next, since James runs 3 sprints per week, we multiply the distance of one sprint by 3:\n",
      "\\[ \\text{Total distance per week} = 60 \\text{ meters/sprint} \\times 3 \\text{ sprints/week} \\]\n",
      "\\[ \\text{Total distance per week} = 180 \\text{ meters} \\]\n",
      "\n",
      "So, the total distance James runs in a week is:\n",
      "\\[\n",
      "\\boxed{180}\n",
      "\\]\n",
      "Ground truth:  540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:06<00:00, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how many cups of feed Wendi needs for the final meal of the day, we can follow these steps:\n",
      "\n",
      "1. Calculate the total amount of feed needed for all the chickens.\n",
      "2. Determine how much feed is given away in the morning and the afternoon.\n",
      "3. Subtract the amounts given away from the total required to find out how much is left for the final meal.\n",
      "\n",
      "First, let's calculate the total amount of feed needed for all the chickens:\n",
      "- Each chicken gets 3 cups of feed per day.\n",
      "- There are 20 chickens in total.\n",
      "\n",
      "So, the total amount of feed needed is:\n",
      "\\[ 20 \\text{ chickens} \\times 3 \\text{ cups/chicken} = 60 \\text{ cups} \\]\n",
      "\n",
      "Next, we calculate the amount of feed given away in the morning and the afternoon:\n",
      "- In the morning: \\( 15 \\text{ cups} \\)\n",
      "- In the afternoon: \\( 25 \\text{ cups} \\)\n",
      "\n",
      "Now, we subtract the amounts given away from the total required:\n",
      "\\[ 60 \\text{ cups} - (15 \\text{ cups} + 25 \\text{ cups}) = 60 \\text{ cups} - 40 \\text{ cups} = 20 \\text{ cups} \\]\n",
      "\n",
      "Therefore, the number of cups of feed Wendi needs to give her chickens in the final meal of the day is:\n",
      "\\[\n",
      "Ground truth:  20\n",
      "Evaluation Accuracy: 20.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Storing predictions and ground truths:\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for example in tqdm(eval_dataset):\n",
    "    #Going through the post processed dataset:\n",
    "    #Extracting the structured prompt that includes the system instruction and user’s math question.\n",
    "    input_prompt = example[\"prompt\"]\n",
    "    #Retrieving the numeric ground truth answer from the processed dataset for later comparison.\n",
    "    ground_truth = example[\"ground_truth\"]\n",
    "    #Runing the model to generate an answer:\n",
    "    with torch.no_grad():\n",
    "        response = generate_responses(model, tokenizer, \n",
    "                                      full_message = input_prompt) \n",
    "    #Appending the generated model response to the list in the same structured format expected by the reward function.\n",
    "    all_preds.append([{\"role\": \"assistant\", \"content\": response}])\n",
    "    #Appending the corresponding ground truth label to the list to align with the prediction order.\n",
    "    all_labels.append(ground_truth)\n",
    "    print(response)\n",
    "    print(\"Ground truth: \", ground_truth)\n",
    "\n",
    "# 3.Evaluating using reward_func\n",
    "#Applying the previously defined reward function to all generated responses and ground truths to compute scores.\n",
    "rewards = reward_func(all_preds, all_labels)\n",
    "\n",
    "# 4. Reporting accuracy:\n",
    "#Calculating overall evaluation accuracy as the proportion of correct responses across all evaluated examples.\n",
    "accuracy = sum(rewards) / len(rewards)\n",
    "print(f\"Evaluation Accuracy: {accuracy:.2%}\")\n",
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eec9d3",
   "metadata": {
    "height": 30
   },
   "source": [
    "#### Until here I have completed designing the evaluation process, and now will do the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b31f32-5eaf-476c-8e91-2e28efdc4d3c",
   "metadata": {},
   "source": [
    "## Loading the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01c515a8-3728-45fa-88cc-6eb4de839839",
   "metadata": {
    "height": 252
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ground_truth': '72', 'prompt': [{'content': 'You are a helpful assistant that solves problems step-by-step. Always include the final numeric answer inside \\\\boxed{}.', 'role': 'system'}, {'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'role': 'user'}]}\n"
     ]
    }
   ],
   "source": [
    "#Downloading the full GSM8K dataset from Hugging Face which contains grade school math problems and their step-by-step solutions.\n",
    "dataset = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "#Selecting the training split of the GSM8K dataset to be used for model training with online reinforcement learning.\n",
    "train_dataset = dataset[\"train\"]\n",
    " \n",
    "# Apply to dataset\n",
    "#Applying the previously defined post_processing function to each sample to extract numeric ground truths and format prompts for training input.\n",
    "train_dataset = train_dataset.map(post_processing)\n",
    "#Removing the original question and answer columns to keep only the structured prompt and ground truth fields needed for training.\n",
    "train_dataset = train_dataset.remove_columns([\"question\", \"answer\"])\n",
    "#Reducing the dataset to the first 10 samples when running on CPU to make the training process faster and lightweight.\n",
    "if not USE_GPU:\n",
    "    train_dataset = train_dataset.select(range(10))\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57436e8c-9b07-4da1-8fae-4430c6617b36",
   "metadata": {},
   "source": [
    "## GRPO Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d678274-5768-4cea-ae20-051488e5d0f3",
   "metadata": {
    "height": 303
   },
   "outputs": [],
   "source": [
    "config = GRPOConfig(\n",
    "    #Accumulating gradients over 8 mini-batches before performing a single weight update to simulate a larger effective batch size and stabilize training.\n",
    "    gradient_accumulation_steps=8,\n",
    "    #Seting the number of samples processed per device in one forward and backward pass to one for low-memory environments like CPU.\n",
    "    per_device_train_batch_size=1,\n",
    "    #Specifying how many responses the model should generate per prompt to form a comparison group in GRPO where rewards are computed relatively among responses.\n",
    "    num_generations=4, # Can set as high as 64 or 128\n",
    "    #Runing one full pass over the training dataset since this demonstration focuses on showing the pipeline rather than long convergence.\n",
    "    num_train_epochs=1,\n",
    "    #Defining a small step size for model weight updates to ensure stable learning during reinforcement optimization.\n",
    "    learning_rate=5e-6,\n",
    "    #Instructing the trainer to log intermediate metrics every two steps to monitor progress frequently during small-scale runs.\n",
    "    logging_steps=2,\n",
    "    #Disables GPU usage if USE_GPU is False ensuring the entire training stays on CPU.\n",
    "    no_cuda= not USE_GPU\n",
    ")\n",
    "#Creating a configuration object for GRPO training containing all major hyperparameters and device setup instructions.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc2d5896-6fd6-43d2-85f1-dacbd594f4cf",
   "metadata": {
    "height": 265
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 107.6589, 'train_samples_per_second': 0.093, 'train_steps_per_second': 0.009, 'train_loss': 0.0, 'completion_length': 168.4375, 'rewards/reward_func': 0.0, 'reward': 0.0, 'reward_std': 0.0, 'kl': 0.0, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1, training_loss=0.0, metrics={'train_runtime': 107.6589, 'train_samples_per_second': 0.093, 'train_steps_per_second': 0.009, 'total_flos': 0.0, 'train_loss': 0.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading a small instruction-tuned model and its tokenizer for GRPO so that training is feasible on CPU-only setups.\n",
    "model, tokenizer = load_model_and_tokenizer(\"./models/HuggingFaceTB/SmolLM2-135M-Instruct\", USE_GPU)\n",
    "\n",
    "grpo_trainer = GRPOTrainer(\n",
    "    #Suppling the policy model whose weights will be updated by GRPO during training.\n",
    "    model=model,\n",
    "    #Passes the GRPO configuration that defines batch size, number of generations per prompt, learning rate, logging steps, and device behavior.\n",
    "    args=config,\n",
    "    #Providing the verifiable reward function that extracts \\boxed{} answers and returns rewards which GRPO will use to compute group-relative advantages.\n",
    "    reward_funcs=reward_func,\n",
    "    #Giving the preprocessed training dataset where each item contains a formatted prompt and a numeric ground truth for reward calculation.\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "#Starting the GRPO training loop where multiple responses per prompt are generated, scored by the reward function, and used to update the policy via relative advantages.\n",
    "grpo_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db7430f",
   "metadata": {
    "height": 30
   },
   "source": [
    "- You might find that the training loss here is always zero. The reason behind this is that we are starting from a very small model, which cannot get most of the question correct. And that's why, in GRRPO the relative reward is all zero, since the model never gets the answers correct. \n",
    "- When you switch to a larger model like Qwen 2.5B, you will see a meaningful training loss and meaningful improvement in the GRPO training process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a33533-3f0c-4d1c-a5ef-f0ba1ff61a5f",
   "metadata": {},
   "source": [
    "## Results of the fully trained Qwen model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08666571-bda3-45f3-99cc-8593c116a115",
   "metadata": {},
   "source": [
    "- Due to limited computational resources, I used a small model and dataset for GRPO training. \n",
    "- The following results are from a fully trained larger model—**Qwen2.5-0.5B**—to demonstrate the complete outcome of the GRPO process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5521a00a-88d8-4ad9-b134-12ea94e76984",
   "metadata": {
    "height": 725
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:11<00:47, 11.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how much Janet makes at the farmers' market each day, we need to follow these steps:\n",
      "\n",
      "1. Calculate the total number of eggs laid by the ducks in one day.\n",
      "   - The ducks lay 16 eggs per day.\n",
      "   - Janet eats 3 eggs in the morning.\n",
      "   - Janet bakes muffins for her friends, which means she doesn't eat any eggs during this time.\n",
      "   - Therefore, the total number of eggs laid is \\(16 - 3 = 13\\) eggs.\n",
      "\n",
      "2. Subtract the number of eggs eaten from the total number of eggs laid.\n",
      "   - Total eggs laid: 13\n",
      "   - Eggs eaten: 3\n",
      "   - Remaining eggs: \\(13 - 3 = 10\\)\n",
      "\n",
      "3. Determine the revenue from selling the remaining eggs at the farmers' market.\n",
      "   - Each egg is sold for $2.\n",
      "   - Revenue = \\(10 \\times 2 = 20\\) dollars.\n",
      "\n",
      "Therefore, the amount Janet makes at the farmers' market each day is \\(\\boxed{20}$.\n",
      "Ground truth:  18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|████      | 2/5 [00:20<00:29,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the total number of bolts of fabric, we need to calculate the amount of blue and white fibers required for each type of robe and then sum them up.\n",
      "\n",
      "1. **Blue Fiber:**\n",
      "   - It takes 2 bolts of blue fiber.\n",
      "   \n",
      "2. **White Fiber:**\n",
      "   - It takes half as much white fiber as blue fiber, so:\n",
      "     \\[\n",
      "     \\frac{2}{2} = 1 \\text{ bolt of white fiber}\n",
      "     \\]\n",
      "\n",
      "Now, let's add the number of bolts of each type:\n",
      "\n",
      "- Total blue bolts: \\(2\\)\n",
      "- Total white bolts: \\(1\\)\n",
      "\n",
      "Therefore, the total number of bolts is:\n",
      "\\[\n",
      "2 + 1 = 3\n",
      "\\]\n",
      "\n",
      "The total number of bolts needed is \\(\\boxed{3}.\n",
      "Ground truth:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|██████    | 3/5 [00:37<00:26, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the profit Josh made, we need to follow these steps:\n",
      "\n",
      "1. Calculate the new value of the house after the repairs.\n",
      "2. Determine the increase in value due to the repairs.\n",
      "3. Find out what the increase in value represents as a percentage of the original value.\n",
      "4. Subtract this percentage from 100% to find the actual profit.\n",
      "\n",
      "Let's start with the first step:\n",
      "The original value of the house is $80,000. After putting in $50,000 in repairs, the new value becomes:\n",
      "\\[ 80,000 + 50,000 = 130,000 \\]\n",
      "\n",
      "Next, we calculate the increase in value due to the repairs:\n",
      "\\[ 130,000 - 80,000 = 50,000 \\]\n",
      "\n",
      "Finally, we find out what this increase represents as a percentage of the original value:\n",
      "\\[ \\frac{50,000}{80,000} \\times 100\\% = 62.5\\% \\]\n",
      "\n",
      "This means the increase in value is equivalent to an additional 62.5% of the original value. To find the actual profit, we subtract this percentage from 100%:\n",
      "\\[ 100\\% - 62.5\\% = 37.5\\% \\]\n",
      "\n",
      "Therefore\n",
      "Ground truth:  70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|████████  | 4/5 [00:47<00:11, 11.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the total distance James runs in a week, we need to follow these steps:\n",
      "\n",
      "1. Calculate the distance James runs in one sprint.\n",
      "   - Each sprint is 60 meters.\n",
      "\n",
      "2. Determine the distance James runs in three sprints.\n",
      "   - Since he runs 3 times per week and each sprint is 60 meters, the total distance for three sprints is \\(3 \\times 60 = 180\\) meters.\n",
      "\n",
      "3. Multiply the weekly distance by the number of sprints.\n",
      "   - The total distance James runs in a week is \\(180 \\text{ meters/sprint} \\times 3 \\text{ sprints/week} = 540\\) meters.\n",
      "\n",
      "Therefore, the total distance James runs in a week is \\(\\boxed{540}$.\n",
      "Ground truth:  540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:58<00:00, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how much feed Wendi needs for the final meal of the day, we first calculate the total amount of feed required.\n",
      "\n",
      "Wendi has 20 chickens, and she feeds each chicken 3 cups of feed per day. Therefore, the total amount of feed needed for all the chickens is:\n",
      "\\[ 20 \\text{ chickens} \\times 3 \\text{ cups/chicken} = 60 \\text{ cups} \\]\n",
      "\n",
      "In the morning, she gives 15 cups of feed.\n",
      "In the afternoon, she gives another 25 cups of feed.\n",
      "So, the total amount of feed given in the final meal of the day is:\n",
      "\\[ 15 \\text{ cups} + 25 \\text{ cups} = 40 \\text{ cups} \\]\n",
      "\n",
      "Therefore, the total number of cups of feed Wendi needs to give her chickens in the final meal of the day is:\n",
      "\\[\n",
      "\\boxed{40}\n",
      "Ground truth:  20\n",
      "Evaluation Accuracy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Seting a flag to choose between evaluating a previously trained GRPO Qwen model or the locally trained small model.\n",
    "fully_trained_qwen = True\n",
    "\n",
    "#Loading the fully trained GRPO Qwen 2.5-0.5B model and its matching tokenizer for evaluation on the math dataset.\n",
    "if fully_trained_qwen:\n",
    "    model, tokenizer = load_model_and_tokenizer(\"./models/banghua/Qwen2.5-0.5B-GRPO\", \n",
    "                                            USE_GPU)\n",
    "#Falling back to the in-session GRPO policy model when a fully trained checkpoint is not available while assuming the tokenizer from earlier remains compatible.\n",
    "else:\n",
    "    model = grpo_trainer.model\n",
    "\n",
    "#Storing predictions and ground truths:\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "#Iterating over the evaluation dataset:\n",
    "for example in tqdm(eval_dataset):\n",
    "    #Retrieving the formatted prompt containing the system instruction and the user’s math question for the current example.\n",
    "    input_prompt = example[\"prompt\"]\n",
    "    #Retrieving the numeric ground truth answer extracted during preprocessing for correctness checking.\n",
    "    ground_truth = example[\"ground_truth\"]\n",
    "    #Runing the model to generate an answer:\n",
    "    #Disabling gradient tracking because I are only generating outputs during evaluation.\n",
    "    with torch.no_grad():\n",
    "        #Generating the assistant's response for the given prompt using the helper that applies the chat template.\n",
    "        response = generate_responses(model, tokenizer, \n",
    "                                      full_message = input_prompt) \n",
    "    #Appending the generated response in chat-format so the reward function can regex-extract the boxed answer.\n",
    "    all_preds.append([{\"role\": \"assistant\", \"content\": response}])\n",
    "    #Appends the corresponding ground truth so predictions and labels have matching order and length.\n",
    "    all_labels.append(ground_truth)\n",
    "    print(response)\n",
    "    print(\"Ground truth: \", ground_truth)\n",
    "\n",
    "# 3. Evaluate using reward_func\n",
    "#Computing rewards by extracting \\boxed{} answers from predictions and comparing them to ground truths returning one for matches and zero for mismatches.\n",
    "rewards = reward_func(all_preds, all_labels)\n",
    "\n",
    "# 4. Report accuracy\n",
    "#Calculating accuracy as the mean of rewards which equals the fraction of correctly answered problems.\n",
    "accuracy = sum(rewards) / len(rewards)\n",
    "print(f\"Evaluation Accuracy: {accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
